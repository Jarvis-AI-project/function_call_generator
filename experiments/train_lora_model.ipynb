{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devasheesh/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/devasheesh/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/devasheesh/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig, \n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TextStreamer, \n",
    "    GenerationConfig, \n",
    "    logging,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from trl import  SFTTrainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import transformers\n",
    "import wandb\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset, random_split\n",
    "from pymilvus import Collection, db, connections\n",
    "import torch\n",
    "import datasets\n",
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevasheeshmishra\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"datasets/synthetic-mt/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BASE_MODEL_PATH = Path('../models/zephyr-7b-beta/')\n",
    "_LORA_OUTPUT_PATH = Path('output/loras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    _BASE_MODEL_PATH,\n",
    "    padding_side=\"right\",\n",
    "    add_eos_token=False,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False\n",
    ")\n",
    "# model_config = AutoConfig.from_pretrained(_BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/zephyr-7b-beta/config.json\n",
      "Model config MistralConfig {\n",
      "  \"_name_or_path\": \"../models/zephyr-7b-beta\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ../models/zephyr-7b-beta/pytorch_model.bin.index.json\n",
      "Instantiating MistralForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3f27b985f7440d95039d6f86c08389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "All the weights of MistralForCausalLM were initialized from the model checkpoint at ../models/zephyr-7b-beta.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "loading configuration file ../models/zephyr-7b-beta/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    _BASE_MODEL_PATH,\n",
    "    # config=base_model_config, \n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "# for param in model.parameters():\n",
    "#     # Turning off gradient calculation for base model as we want to train lora, not base model\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'<s>': 1}, {'</s>': 2}, {'</s>': 2}, {'<unk>': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{tokenizer.bos_token: tokenizer.bos_token_id}, \\\n",
    "{tokenizer.eos_token: tokenizer.eos_token_id}, \\\n",
    "{tokenizer.pad_token: tokenizer.pad_token_id}, \\\n",
    "{tokenizer.unk_token: tokenizer.unk_token_id},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.do_sample=False\n",
    "# model.generation_config.do_sample=False\n",
    "# model.config.temperature=0.0\n",
    "# model.generation_config.temperature=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.add_tokens([\"<calculator>\", \"</calculator>\"])\n",
    "# print(f\"Token: {tokenizer.tokenize('<calculator>')} | ID: {tokenizer.convert_tokens_to_ids('<calculator>')}\")\n",
    "# print(f\"Token: {tokenizer.tokenize('</calculator>')} | ID: {tokenizer.convert_tokens_to_ids('</calculator>')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a Personal Assistant named JARVIS. You are installed in Devasheesh Mishra's House and running on his servers. You are integrated in his smart home system. If he is generally talking about something, just talk to him but if he is asking to control the state of a device, you first need to ask the system to give you the functions needed to control the device, then you can do the appropriate function call to control devices. You can also ask user for more information if needed. You can also use tools like 1. calculator (for doing basic mathematical calculations i.e. addition, substraction, multiplication, division) 2. calendar (to find todays date) 3. clock (to find todays day and current time). You can also use Google to search for Information online. Give short responses as much as possible. Be attentive to user commands and inquiries, ensuring a seamless and efficient smart home experience. You are designed to make his life easier and better.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_DEVICE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "EPOCHS = 2\n",
    "WARMUP_STEPS = 0\n",
    "LEARNING_RATE = 2e-4\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Zephyr Model Prompt Template:\n",
    "```text\n",
    "<|system|>\n",
    "You are a friendly chatbot who always responds in the style of a pirate.</s>\n",
    "<|user|>\n",
    "How many helicopters can a human eat in one sitting?</s>\n",
    "<|assistant|>\n",
    "Ah, me hearty matey! But yer question be a puzzler! A human cannot eat a helicopter in one sitting, as helicopters are not edible. They be made of metal, plastic, and other materials, not food!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MilvusDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        connections.connect(\n",
    "            alias=\"default\",\n",
    "            host = os.getenv(\"MILVUS_HOST\"),\n",
    "            port = 19530,\n",
    "            user=os.getenv(\"MILVUS_USER\"),\n",
    "            password=os.getenv(\"MILVUS_PASSWORD\"),\n",
    "        )\n",
    "        db.using_database(\"JARVIS\")\n",
    "        self.collection = Collection(\"calculator\")\n",
    "        self.data_itrator = self.collection.query_iterator(\n",
    "                                batch_size=1,\n",
    "                                output_fields=[\"conversation\"],\n",
    "                                expr=\"conversation_id > 0\",\n",
    "                            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.collection.num_entities\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conversation: dict = self.data_itrator.next()[0]\n",
    "        conversation = self.apply_prompt_template(conversation)\n",
    "        return conversation\n",
    "        # return {\n",
    "        #         'input_ids': conversation['input_ids'].squeeze(),\n",
    "        #         'attention_mask': conversation['attention_mask'].squeeze(),\n",
    "        #     }\n",
    "        # return {\n",
    "        #         'input_ids': torch.tensor(conversation['input_ids'], device=base_model.device), \n",
    "        #         'attention_mask': torch.tensor(conversation['attention_mask'], device=base_model.device)\n",
    "        #     }\n",
    "\n",
    "    def apply_prompt_template(self, conversation: dict):\n",
    "        # add </s> at end of lines which do not end with </s>\n",
    "        conversation[\"conversation\"][\"data\"] = ''.join([x + '</s>\\n' if not x.strip().endswith(\"</s>\") else x + '\\n' for x in conversation[\"conversation\"][\"data\"].split(\"\\n\")]).strip()\n",
    "\n",
    "        # apply zephyr-7b-beta chat template\n",
    "        prompt = f\"<|system|>\\n{SYSTEM_PROMPT}</s>\\n{conversation[\"conversation\"][\"data\"].replace(\"USER: \", \"<|user|>\\n\").replace(\"ASSISTANT: \", \"<|assistant|>\\n\")}\"\n",
    "        return prompt\n",
    "        # return tokenizer(prompt, return_tensors=\"pt\", padding=True).to(base_model.device)\n",
    "        # return tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Gradient Accumulation](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-accumulation)\n",
    "    The idea behind gradient accumulation is to instead of calculating the gradients for the whole batch at once to do it in smaller steps. The way we do that is to calculate the gradients iteratively in smaller batches by doing a forward and backward pass through the model and accumulating the gradients in the process. When enough gradients are accumulated we run the model’s optimization step. This way we can easily increase the overall batch size to numbers that would never fit into the GPU’s memory. In turn, however, the added forward and backward passes can slow down the training a bit.\n",
    "\n",
    "### [Gradient Checkpointing](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-checkpointing)\n",
    "    Even when we set the batch size to 1 and use gradient accumulation we can still run out of memory when working with large models. In order to compute the gradients during the backward pass all activations from the forward pass are normally saved. This can create a big memory overhead. Alternatively, one could forget all activations during the forward pass and recompute them on demand during the backward pass. This would however add a significant computational overhead and slow down training.\n",
    "\n",
    "    Gradient checkpointing strikes a compromise between the two approaches and saves strategically selected activations throughout the computational graph so only a fraction of the activations need to be re-computed for the gradients. See this great article explaining the ideas behind gradient checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.gradient_checkpointing_enable()\n",
    "# base_model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@manyi.yim/more-about-loraconfig-from-peft-581cf54643db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940290959023318\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    # peft_type: str | PeftType = None,\n",
    "    # auto_mapping: dict | None = None,\n",
    "    base_model_name_or_path = 'zephyr-7b-beta',\n",
    "    # revision: str = None,\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    "    # inference_mode: bool = False,\n",
    "    r = 16, #! 8, 16, 32, 64\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    lora_alpha = 32, #! 8, 16, 32\n",
    "    lora_dropout = 0.05,\n",
    "    # fan_in_fan_out: bool = False,\n",
    "    bias = \"none\",\n",
    "    # modules_to_save: List[str] | None = None,\n",
    "    # init_lora_weights: bool = True,\n",
    "    # layers_to_transform: List[int] | int | None = None,\n",
    "    # layers_pattern: str | None = None\n",
    ")\n",
    "model = get_peft_model(model, lora_config, adapter_name='jarvis-calculator-v0_1')\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.0.input_layernorm.weight False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.1.input_layernorm.weight False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.2.input_layernorm.weight False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.3.input_layernorm.weight False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.4.input_layernorm.weight False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.5.input_layernorm.weight False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.6.input_layernorm.weight False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.7.input_layernorm.weight False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.8.input_layernorm.weight False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.9.input_layernorm.weight False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.10.input_layernorm.weight False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.11.input_layernorm.weight False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.12.input_layernorm.weight False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.13.input_layernorm.weight False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.14.input_layernorm.weight False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.15.input_layernorm.weight False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.16.input_layernorm.weight False\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.17.input_layernorm.weight False\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.18.input_layernorm.weight False\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.19.input_layernorm.weight False\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.20.input_layernorm.weight False\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.21.input_layernorm.weight False\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.22.input_layernorm.weight False\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.23.input_layernorm.weight False\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.24.input_layernorm.weight False\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.25.input_layernorm.weight False\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.26.input_layernorm.weight False\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.27.input_layernorm.weight False\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.28.input_layernorm.weight False\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.29.input_layernorm.weight False\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.30.input_layernorm.weight False\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight False\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight False\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.weight False\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight False\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.jarvis-calculator-v0_1.weight True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight False\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight False\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight False\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight False\n",
      "base_model.model.model.layers.31.input_layernorm.weight False\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight False\n",
      "base_model.model.model.norm.weight False\n",
      "base_model.model.lm_head.weight False\n"
     ]
    }
   ],
   "source": [
    "for parm in model.named_parameters():\n",
    "    print(parm[0], parm[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MilvusDataset()\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training, 20% for testing\n",
    "test_size = total_size - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = list(train_dataset), list(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = [{\"text\": text} for text in train_dataset], [{\"text\": text} for text in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = datasets.Dataset.from_list(train_dataset), datasets.Dataset.from_list(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.decode(train_dataset[4]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you ran this function, you will need to rerun the cell above to get the train_dataset and test_dataset\n",
    "# def plot_data_lengths(dataset):\n",
    "#     lengths = [len(x['input_ids']) for x in dataset]\n",
    "#     print(len(lengths))\n",
    "\n",
    "#     # Plotting the histogram\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.hist(lengths, bins=40, alpha=0.7, color='blue')\n",
    "#     plt.xlabel('Length of input_ids')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.title('Distribution of Lengths of input_ids')\n",
    "#     plt.show()\n",
    "\n",
    "# plot_data_lengths(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "run_name = \"calculator-lora\"\n",
    "training_args = TrainingArguments(\n",
    "    # Training\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
    "    per_device_train_batch_size=BATCH_SIZE_PER_DEVICE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    fp16=True,\n",
    "\n",
    "    # Evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    \n",
    "    # Logging and Saving\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    output_dir=_LORA_OUTPUT_PATH,\n",
    "    save_steps=10,\n",
    "    \n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset['text'],\n",
    "#     eval_dataset=test_dataset['text'],\n",
    "#     data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea7ebd4429649759f386e6ce8854de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34183686f924906a0645ed4a4154d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 43\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22\n",
      "  Number of trainable parameters = 6,815,744\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/nvme/JARVIS/function_call_generator/experiments/wandb/run-20240117_164513-fzalyrht</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/devasheeshmishra/huggingface/runs/fzalyrht' target=\"_blank\">calculator-lora-2024-01-17-16-45</a></strong> to <a href='https://wandb.ai/devasheeshmishra/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/devasheeshmishra/huggingface' target=\"_blank\">https://wandb.ai/devasheeshmishra/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/devasheeshmishra/huggingface/runs/fzalyrht' target=\"_blank\">https://wandb.ai/devasheeshmishra/huggingface/runs/fzalyrht</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devasheesh/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH,\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:315\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 315\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/transformers/trainer.py:2734\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2734\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/accelerate/accelerator.py:1903\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1903\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1905\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/site-packages/torch/autograd/graph.py:690\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    dataset_text_field='text',\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=False,\n",
    "    max_seq_length=MAX_LENGTH,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.0.dev20240117', '4.35.2', '0.7.1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import peft\n",
    "torch.__version__, transformers.__version__, peft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('birgermoell/open_assistant_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning and preprocessing functions.\n",
    "def text_to_dialogue(text):\n",
    "    return [sentence.replace('User:', '').replace('Chip:', '').strip() for sentence in text.split('Assistant:')]\n",
    "\n",
    "def dialogue_to_chat(dialogue):\n",
    "    out = [{'role': 'system', 'content': 'You are a friendly chatbot assistant.'}]\n",
    "    for idx, message in enumerate(dialogue):\n",
    "        role = 'user' if idx%2==0 else 'assistant'\n",
    "        out.append({'role': role, 'content': message})\n",
    "    return out\n",
    "\n",
    "def chat_to_input(chat):\n",
    "    return tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "\n",
    "def process_example(example):\n",
    "    out = text_to_dialogue(example)             # Clean up data from redundant words\n",
    "    out = dialogue_to_chat(out)                 # Convert to ChatML format\n",
    "    out = chat_to_input(out)                    # Add a task description & Apply base model chat template\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on dataset.\n",
    "data = list(map(process_example, df['text']))\n",
    "\n",
    "# Shuffle dataset.\n",
    "from random import shuffle\n",
    "shuffle(data)\n",
    "\n",
    "# Tokenize data.\n",
    "tokenized_data = list(map(tokenizer, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(.99 * len(data))\n",
    "train_data, val_data = tokenized_data[:split_idx], tokenized_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(dataset[0]['input_ids'])), print(tokenizer.decode(train_data[811]['input_ids']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
