{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import asyncio\n",
    "import re\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility, db\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUERIES_PER_MINUTE = 60\n",
    "DATABASE_NAME = 'CUSTOM_DATASETS'\n",
    "COLLECTION_NAME = 'calculator_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Generate a sample Multi-Turn conversation between a user and a voice assistant named JARVIS in which the voice assistant has the capability of using a calculator. The assistant has a frank personality and is very helpful.\n",
    "The calculator can perform these arithmetic operations.\n",
    "1. Addition (+): adds two operands\n",
    "2. Subtraction (-): subtracts two operands\n",
    "3. Multiplication (*): multiplies two operands\n",
    "4. Division (/): divides two operands\n",
    "5. Modulus (%): returns the remainder when the first operand is divided by the second\n",
    "6. Floor division (//): returns the quotient when the first operand is divided by the second\n",
    "7. Exponent (**): returns the first operand raised to the power of the second operand\n",
    "\n",
    "Note: This calculator works on the BODMAS rule which means multiplication and division are performed before addition and subtraction.\n",
    "Example Usage:\n",
    "<calculator>2+3</calculator>\n",
    "\n",
    "Note: If you need to use two or more operators in a single expression, you need to apply brackets to specify the order of operations.\n",
    "Precedence of operators:\n",
    "1. Exponentiation (**)\n",
    "2. Multiplication (*), Division (/), Floor division (//), and Modulus (%)\n",
    "3. Addition (+) and Subtraction (-)\n",
    "Example Usage:\n",
    "<calculator>2+(3*4)</calculator> Here, 3 and 4 will be multiplied first and then the result will be added to 2.\n",
    "\n",
    "<|user|>\n",
    "Hey, buddy, I'm planning a road trip, and I want to calculate the total distance I'll be driving. The trip involves multiple stops, and I have the distances between each pair of stops. Can you help me find the total distance?\n",
    "<|assistant|>\n",
    "Absolutely! I'd be happy to assist. Could you provide me with the distances between each pair of stops and the list of stops on your road trip?</s>\n",
    "<|user|>\n",
    "Sure, Home to Gas Station is 10 miles Gas Station to Mountain View is 30 miles Mountain View to Lakeside Park is 15 miles Lakeside Park to Beach Resort is 25 miles Beach Resort to Home is 40 miles.\n",
    "<|assistant|>\n",
    "Great, Let me calculate the total distance for you. <calculator>10+30+15+25+40<stop>120</calculator>The total distance is 120 miles. Is there anything else I can help you with?</s>\n",
    "<|user|>\n",
    "That's perfect. One more thing, what's the average speed I should maintain if I want to reach the Beach Resort in 2 hours?\n",
    "<|assistant|>\n",
    "Let me calculate that for you. <calculator>120/2<stop>60</calculator>You should maintain an average speed of 60 miles per hour. Is there anything else I can help you with?</s>\n",
    "<|user|>\n",
    "That's all I need. Thanks for your help.\n",
    "<|assistant|>\n",
    "You're welcome. Have a great trip! Drive Safe, and feel free to ask for any help.</s>\n",
    "\n",
    "Generate more such conversations to train the assistant. \n",
    "- The main calculation should be surrounded by \"<calculator>\" and \"</calculator>\" which will not be shown to the user and is evaluated by a computer. \n",
    "- Assume this system is being used to do day-to-day tasks.\n",
    "- Do not explain your calculation to the user.\n",
    "- Avoid generating data points that require up-to-date knowledge.\n",
    "- User query can't contain any kind of symbols such as (%, $,₹, .,), etc. Instead, it should use the corresponding word representation of the symbols eg. dollar for $ and percentage for %\n",
    "- If the user query contains currency or a number, convert it into words eg. ₹100 -> one Hundred rupees, 3500 rupees -> thirty-five hundred rupees, ₹500 -> five hundred rupees, ₹.25 -> twenty-five paisa.\n",
    "- Try to use currency as rupees\n",
    "- the user query should not contain or end with \"</s>\" or \"<stop>\"\n",
    "- Assistant response should end with \"</s>\"\n",
    "- the assistant response should contain \"<stop>\" after the expression in between the opening and closing tags of \"<calculator>\" and \"</calculator>\". eg. ASSISTANT: The cost of a dozen eggs would be <calculator>1*12<stop>12</calculator>twelve rupees.</s>\n",
    "- If calculator gives a float value, round it accordingly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting API Keys and Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=os.getenv(\"MILVUS_HOST\"),\n",
    "    port=os.getenv(\"MILVUS_PORT\"),\n",
    "    user=os.getenv(\"MILVUS_USER\"),\n",
    "    password=os.getenv(\"MILVUS_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Milvus Database to store embeddings and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATABASE_NAME in db.list_database():\n",
    "    db.create_database(DATABASE_NAME)\n",
    "db.using_database(DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection calculator_v1 created successfully.\n",
      "Collection calculator_v1 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if not COLLECTION_NAME in utility.list_collections():\n",
    "    # Create collection\n",
    "    conversation_id = FieldSchema(\n",
    "        name=\"conversation_id\", \n",
    "        dtype=DataType.INT64, \n",
    "        is_primary=True, \n",
    "        auto_id=True, \n",
    "        description=\"Unique id for each conversation\"\n",
    "    )\n",
    "    embeding = FieldSchema(\n",
    "        name=\"embeding\", \n",
    "        dtype=DataType.FLOAT_VECTOR, \n",
    "        dim=1536,\n",
    "        description=\"Embedings generated using text-embedding-ada-002-v2\"\n",
    "    )\n",
    "    conversation = FieldSchema(\n",
    "        name=\"conversation\",\n",
    "        dtype=DataType.VARCHAR,\n",
    "        max_length=4096,\n",
    "        description=\"Conversation between user and assistant\"\n",
    "    )\n",
    "\n",
    "    schema = CollectionSchema(fields=[conversation_id, embeding, conversation], description=SYSTEM_PROMPT)\n",
    "\n",
    "    collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "    collection.create_index(\n",
    "        field_name=\"embeding\", \n",
    "        index_params={\n",
    "            \"index_type\": \"IVF_FLAT\",\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"nlist\": 128}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f'Collection {COLLECTION_NAME} created successfully.')\n",
    "\n",
    "else:\n",
    "    collection = Collection(name=COLLECTION_NAME)\n",
    "\n",
    "collection.load()\n",
    "print(f'Collection {COLLECTION_NAME} loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get embeddings from OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=[text]\n",
    "    ).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 1,\n",
    "    \"max_output_tokens\": 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant_response_endswith_eos_token(text: str):\n",
    "    # Matches all the assistant responses in the text except the last one\n",
    "    expr = r'<\\|assistant\\|>\\n(.*?)<\\|user\\|>'\n",
    "    assistant_responses = [x.strip() for x in re.findall(expr, text, re.DOTALL)]\n",
    "    # Last assistant response\n",
    "    assistant_responses.append(text.split('<|assistant|>')[-1].strip())\n",
    "    return not all([x.endswith('</s>') for x in assistant_responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_token_between_calculator_tags(text):\n",
    "    expr = r'<calculator>(.*?)</calculator>'\n",
    "    calculator_expressions = [x.strip() for x in re.findall(expr, text)]\n",
    "    return not all([x.count('<stop>') == 1 for x in calculator_expressions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_open_calc_tags_equal_number_of_close_calc_tags(text):\n",
    "    return not text.count('<calculator>') == text.count('</calculator>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_calculator_calculation_correct(text, debug=False):\n",
    "#     expr = r'<calculator>(.*?)<stop>(.*?)</calculator>'\n",
    "#     calculator_expressions = re.findall(expr, text)\n",
    "#     if debug:\n",
    "#         return [f'{x} -> {eval(x[0]) == eval(x[1])}' for x in calculator_expressions]\n",
    "#     return not all([eval(x[0]) == eval(x[1]) for x in calculator_expressions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_should_not_contain_special_token(text):\n",
    "    spl_tokens = ['<s>', '</s>', '<unk>', '<calculator>', '</calculator>', '<stop>']\n",
    "    expr = r'<\\|user\\|>\\n(.*?)<\\|assistant\\|>'\n",
    "    user_inputs = [x.strip() for x in re.findall(expr, text)]\n",
    "    return not all([not any([x.count(y) > 0 for y in spl_tokens]) for x in user_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_user_inputs_equal_number_of_assistant_responses(text):\n",
    "    return not text.count('<|user|>') == text.count('<|assistant|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_response(text):\n",
    "    return assistant_response_endswith_eos_token(text) or stop_token_between_calculator_tags(text) or number_of_open_calc_tags_equal_number_of_close_calc_tags(text) or user_input_should_not_contain_special_token(text) or number_of_user_inputs_equal_number_of_assistant_responses(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_point():\n",
    "    try:\n",
    "        response = model.generate_content(SYSTEM_PROMPT)\n",
    "        embeding = get_embeding(response.text)\n",
    "        if not test_response(response.text):\n",
    "            collection.insert({\n",
    "                \"embeding\": embeding,\n",
    "                \"conversation\": response.text\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_insert_data_point():\n",
    "    while True:\n",
    "        await insert_data_point()\n",
    "        await asyncio.sleep(1/MAX_QUERIES_PER_MINUTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[334], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_insert_data_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_insert_data_point())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "function_call_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
