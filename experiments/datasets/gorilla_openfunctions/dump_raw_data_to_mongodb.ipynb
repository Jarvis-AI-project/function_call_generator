{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URI = f\"mongodb://{os.environ['MONGODB_USERNAME']}:{os.environ['MONGODB_PASSWORD']}@{os.environ['MONGODB_HOST']}:{os.environ['MONGODB_PORT']}/{os.environ['MONGODB_DATABASE']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'function_calling', 'local', 'mqtt_logs']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient(_URI)\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[\"function_calling\"]\n",
    "collection = db[\"gorilla_openfunctions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursively_dump_to_json(input_json_str):\n",
    "    # Parse the outer JSON string\n",
    "    input_json_str = str(input_json_str)\n",
    "    input_json_str = input_json_str.strip()\n",
    "    try:\n",
    "        outer_data = json.loads(input_json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"data\": input_json_str\n",
    "        }\n",
    "\n",
    "    # Function to recursively convert inner JSON strings\n",
    "    def convert_inner_json(obj):\n",
    "        if isinstance(obj, str):\n",
    "            obj = obj.strip()\n",
    "            if obj.startswith(\"{\") and obj.endswith(\"}\"):\n",
    "                try:\n",
    "                    return json.loads(obj)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing JSON: {e}\")\n",
    "                    raise e\n",
    "            elif obj.startswith(\"[\") and obj.endswith(\"]\"):\n",
    "                try:\n",
    "                    return eval(obj)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating List: {e}\")\n",
    "                    raise e\n",
    "            \n",
    "            return obj\n",
    "            \n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_inner_json(item) for item in obj]\n",
    "        \n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_inner_json(value) for key, value in obj.items()}\n",
    "\n",
    "    # Recursively convert inner JSON strings\n",
    "    converted_data = convert_inner_json(outer_data)\n",
    "    \n",
    "    return dict(converted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate key error at line 1\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 2\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 3\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 4\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 5\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 6\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 7\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 8\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 9\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 10\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 11\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 12\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 13\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 14\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 15\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 16\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 17\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 18\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 19\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 20\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 21\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 22\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 23\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 24\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 25\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 26\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 27\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 28\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 29\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 30\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 31\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 32\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 33\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 34\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 35\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 36\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 37\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 38\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 39\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 40\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 41\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 42\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 43\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 44\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 45\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 46\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 47\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 48\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 49\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 50\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 51\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 52\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 53\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 54\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 55\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 56\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 57\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 58\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 59\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 60\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 61\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 62\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 63\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 64\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 65\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 66\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 67\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 68\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 69\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 70\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 71\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 72\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 73\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 74\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 75\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 76\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 77\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 78\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 79\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 80\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 81\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 82\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 83\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 84\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 85\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 86\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 87\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 88\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 89\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 90\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 91\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 92\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 93\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 94\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 95\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 96\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 97\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 98\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 99\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 100\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 101\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 102\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 103\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 104\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 105\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 106\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 107\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 108\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 109\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 110\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 111\n",
      "Duplicate element is same, skipping\n",
      "Duplicate key error at line 112\n",
      "Duplicate element is same, skipping\n"
     ]
    }
   ],
   "source": [
    "with open(os.environ[\"TEST_FILE_PATH\"]) as f:\n",
    "    for num, data in enumerate(f.readlines()):\n",
    "        \n",
    "        if data.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        # if collection.count_documents({\"split\": \"test\", \"line\": num+1}) > 0:\n",
    "        #     collection.delete_many({\"split\": \"test\", \"line\": num+1})\n",
    "\n",
    "        data = recursively_dump_to_json(data)\n",
    "        \n",
    "        try:\n",
    "            collection.insert_one(\n",
    "                {\n",
    "                    \"split\": \"test\",\n",
    "                    \"line\": num+1,\n",
    "                    \"data\": data\n",
    "                }\n",
    "            )\n",
    "        except pymongo.errors.DuplicateKeyError:\n",
    "            print(f\"Duplicate key error at line {num+1}\")\n",
    "            # Get the duplcate element\n",
    "            duplicate_element = collection.find_one({\"split\": \"test\", \"line\": num+1})\n",
    "            if duplicate_element[\"data\"] != data:\n",
    "                print(\"Duplicate element is different\")\n",
    "                print(f\"Old element: {duplicate_element}\")\n",
    "                print(f\"New element: {data}\")\n",
    "                print(\"Deleting old element and inserting new element\")\n",
    "                collection.delete_one({\"split\": \"test\", \"line\": num+1})\n",
    "                collection.insert_one(\n",
    "                    {\n",
    "                        \"split\": \"test\",\n",
    "                        \"line\": num+1,\n",
    "                        \"data\": data\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                print(\"Duplicate element is same, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {\"Instruction\": \"I want to create a one-dimensional tensor with evenly spaced values from 0 to 1 using the torch.linspace API.\\n\", \"Functions\": [\"{'name': 'Torch', 'api_name': 'torch.linspace', 'description': 'Create a one-dimensional tensor with evenly spaced values', 'parameters': {'start': {'type': 'float', 'description': 'The starting value for the set of points'}, 'end': {'type': 'float', 'description': 'The ending value for the set of points'}, 'steps': {'type': 'int', 'description': 'The number of evenly spaced values to generate'}, 'out': {'type': 'Tensor', 'description': 'Optional output tensor'}, 'dtype': {'type': 'torch.dtype', 'description': 'Optional data type for the computation'}, 'layout': {'type': 'torch.layout', 'description': 'Optional layout of the returned tensor'}, 'device': {'type': 'torch.device', 'description': 'Optional device for the returned tensor'}, 'requires_grad': {'type': 'bool', 'description': 'Optional flag to enable gradient tracking'}}}\\n\", \"{'name': 'RapidAPI', 'api_name': 'requests.get', 'description': 'NOTE: You need an API-Key to use this API. See README for more details.\\\\r\\\\nThe Cancer Imaging Archive (TCIA) is a public repository of cancer images and related clinical data for the express purpose of enabling open science research. Currently over 26 million radiologic images of cancer are contained in this repository. The API allows you to query metadata and download images from the various public collections available on TCIA', 'parameters': [{'name': 'format', 'description': 'Specify output type. Allowed values CSV/HTML/XML/JSON', 'type': 'STRING'}]}\\n\", \"{'name': 'pyarrow', 'api_name': 'read_tensor', 'description': 'Read pyarrow.Tensor from pyarrow.NativeFile object from current position', 'parameters': {'required': [{'name': 'source', 'description': 'pyarrow.NativeFile object'}], 'optional': []}}\\n\", \"{'name': 'alpha', 'api_name': 'gcloud.alpha.builds.enterprise_config.bitbucketserver.delete', 'description': 'Delete a Bitbucket Server config from Google Cloud Build', 'parameters': [{'name': 'config', 'description': 'The id of the Bitbucket Server Config'}, {'name': 'region', 'description': 'The region of the Cloud Build Service to use. Must be set to a supported region name (e.g. us-central1). If unset, builds/region, which is the default region to use when working with Cloud Build resources, is used. If builds/region is unset, region is set to global.'}]}\\n\", \"{'name': 'aws', 'api_name': 'aws.es.describe_domain_auto_tunes', 'description': 'Provides scheduled Auto-Tune action details for the Elasticsearch domain, such as Auto-Tune action type, description, severity, and scheduled date.', 'parameters': [{'name': 'domain_name', 'description': 'Specifies the domain name for which you want Auto-Tune action details.'}, {'name': 'max_results', 'description': 'Set this value to limit the number of results returned. If not specified, defaults to 100.'}, {'name': 'next_token', 'description': 'NextToken is sent in case the earlier API call results contain the NextToken. It is used for pagination.'}]}\"], \"Output\": [\"torch.linspace(start=0,end=1,steps=10)\"]}\n",
      "Error parsing JSON: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# collection.insert_one(\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     {\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         \"split\": \"train\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, data\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m---> 18\u001b[0m \u001b[43mrecursively_dump_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 40\u001b[0m, in \u001b[0;36mrecursively_dump_to_json\u001b[0;34m(input_json_str)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: convert_inner_json(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Recursively convert inner JSON strings\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_inner_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mouter_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(converted_data)\n",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m, in \u001b[0;36mrecursively_dump_to_json.<locals>.convert_inner_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [convert_inner_json(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mconvert_inner_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[23], line 34\u001b[0m, in \u001b[0;36mrecursively_dump_to_json.<locals>.convert_inner_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mconvert_inner_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: convert_inner_json(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m, in \u001b[0;36mrecursively_dump_to_json.<locals>.convert_inner_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError parsing JSON: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mrecursively_dump_to_json.<locals>.convert_inner_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError parsing JSON: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/function_call_generator/lib/python3.12/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "with open(os.environ[\"TRAIN_FILE_PATH\"]) as f:\n",
    "    for num, data in enumerate(f.readlines()):\n",
    "        \n",
    "        if data.strip() == \"\":\n",
    "            continue\n",
    "        \n",
    "        if collection.count_documents({\"split\": \"train\", \"line\": num+1}) > 0:\n",
    "            collection.delete_many({\"split\": \"train\", \"line\": num+1})\n",
    "            \n",
    "        # collection.insert_one(\n",
    "        #     {\n",
    "        #         \"split\": \"train\",\n",
    "        #         \"line\": num+1,\n",
    "        #         \"raw_data\": recursively_dump_to_json(data)\n",
    "        #     }\n",
    "        # )\n",
    "        print(num+1, data.strip())\n",
    "        recursively_dump_to_json(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "function_call_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
