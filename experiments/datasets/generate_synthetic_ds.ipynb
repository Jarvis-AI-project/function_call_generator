{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from threading import Thread\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility, db\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUERIES_PER_MINUTE = 60\n",
    "DATABASE_NAME = 'CUSTOM_DATASETS'\n",
    "COLLECTION_NAME = 'calculator_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Generate a sample Multi-Turn conversation between a user and a voice assistant named JARVIS in which the voice assistant has the capability of using a calculator. The assistant has a frank personality and is very helpful.\n",
    "The calculator can perform these arithmetic operations.\n",
    "1. Addition (+): adds two operands\n",
    "2. Subtraction (-): subtracts two operands\n",
    "3. Multiplication (*): multiplies two operands\n",
    "4. Division (/): divides two operands\n",
    "5. Modulus (%): returns the remainder when the first operand is divided by the second\n",
    "6. Floor division (//): returns the quotient when the first operand is divided by the second\n",
    "7. Exponent (**): returns the first operand raised to the power of the second operand\n",
    "\n",
    "Note: This calculator works on the BODMAS rule which means multiplication and division are performed before addition and subtraction.\n",
    "Example Usage:\n",
    "<calculator>2+3</calculator>\n",
    "\n",
    "Note: If you need to use two or more operators in a single expression, you need to apply brackets to specify the order of operations.\n",
    "Precedence of operators:\n",
    "1. Exponentiation (**)\n",
    "2. Multiplication (*), Division (/), Floor division (//), and Modulus (%)\n",
    "3. Addition (+) and Subtraction (-)\n",
    "Example Usage:\n",
    "<calculator>2+(3*4)</calculator> Here, 3 and 4 will be multiplied first and then the result will be added to 2.\n",
    "\n",
    "<|user|>\n",
    "Hey, buddy, I'm planning a road trip, and I want to calculate the total distance I'll be driving. The trip involves multiple stops, and I have the distances between each pair of stops. Can you help me find the total distance?\n",
    "<|assistant|>\n",
    "Absolutely! I'd be happy to assist. Could you provide me with the distances between each pair of stops and the list of stops on your road trip?</s>\n",
    "<|user|>\n",
    "Sure, Home to Gas Station is 10 miles Gas Station to Mountain View is 30 miles Mountain View to Lakeside Park is 15 miles Lakeside Park to Beach Resort is 25 miles Beach Resort to Home is 40 miles.\n",
    "<|assistant|>\n",
    "Great, Let me calculate the total distance for you. <calculator>10+30+15+25+40<stop>120</calculator>The total distance is 120 miles. Is there anything else I can help you with?</s>\n",
    "<|user|>\n",
    "That's perfect. One more thing, what's the average speed I should maintain if I want to reach the Beach Resort in 2 hours?\n",
    "<|assistant|>\n",
    "Let me calculate that for you. <calculator>120/2<stop>60</calculator>You should maintain an average speed of 60 miles per hour. Is there anything else I can help you with?</s>\n",
    "<|user|>\n",
    "That's all I need. Thanks for your help.\n",
    "<|assistant|>\n",
    "You're welcome. Have a great trip! Drive Safe, and feel free to ask for any help.</s>\n",
    "\n",
    "Generate more such conversations to train the assistant. \n",
    "- The main calculation should be surrounded by \"<calculator>\" and \"</calculator>\" which will not be shown to the user and is evaluated by a computer. \n",
    "- Assume this system is being used to do day-to-day tasks.\n",
    "- Do not explain your calculation to the user.\n",
    "- Avoid generating data points that require up-to-date knowledge.\n",
    "- User query can't contain any kind of symbols such as (%, $,₹, .,), etc. Instead, it should use the corresponding word representation of the symbols eg. dollar for $ and percentage for %\n",
    "- If the user query contains currency or a number, convert it into words eg. ₹100 -> one Hundred rupees, 3500 rupees -> thirty-five hundred rupees, ₹500 -> five hundred rupees, ₹.25 -> twenty-five paisa.\n",
    "- Try to use currency as rupees\n",
    "- the user query should not contain or end with \"</s>\" or \"<stop>\"\n",
    "- Assistant response should end with \"</s>\"\n",
    "- the assistant response should contain \"<stop>\" after the expression in between the opening and closing tags of \"<calculator>\" and \"</calculator>\". eg. ASSISTANT: The cost of a dozen eggs would be <calculator>1*12<stop>12</calculator>twelve rupees.</s>\n",
    "- If calculator gives a float value, round it accordingly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting API Keys and Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=os.getenv(\"MILVUS_HOST\"),\n",
    "    port=os.getenv(\"MILVUS_PORT\"),\n",
    "    user=os.getenv(\"MILVUS_USER\"),\n",
    "    password=os.getenv(\"MILVUS_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Milvus Database to store embeddings and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATABASE_NAME in db.list_database():\n",
    "    db.create_database(DATABASE_NAME)\n",
    "db.using_database(DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection calculator_v1_2 created successfully.\n",
      "Collection calculator_v1_2 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if not COLLECTION_NAME in utility.list_collections():\n",
    "    # Create collection\n",
    "    conversation_id = FieldSchema(\n",
    "        name=\"conversation_id\", \n",
    "        dtype=DataType.INT64, \n",
    "        is_primary=True, \n",
    "        auto_id=True, \n",
    "        description=\"Unique id for each conversation\"\n",
    "    )\n",
    "    embeding = FieldSchema(\n",
    "        name=\"embeding\", \n",
    "        dtype=DataType.FLOAT_VECTOR, \n",
    "        dim=1536,\n",
    "        description=\"Embedings generated using text-embedding-ada-002-v2\"\n",
    "    )\n",
    "    conversation = FieldSchema(\n",
    "        name=\"conversation\",\n",
    "        dtype=DataType.VARCHAR,\n",
    "        max_length=4096,\n",
    "        description=\"Conversation between user and assistant\"\n",
    "    )\n",
    "\n",
    "    schema = CollectionSchema(fields=[conversation_id, embeding, conversation], description=SYSTEM_PROMPT)\n",
    "\n",
    "    collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "    collection.create_index(\n",
    "        field_name=\"embeding\", \n",
    "        index_params={\n",
    "            \"index_type\": \"IVF_FLAT\",\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"nlist\": 128}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f'Collection {COLLECTION_NAME} created successfully.')\n",
    "\n",
    "else:\n",
    "    collection = Collection(name=COLLECTION_NAME)\n",
    "\n",
    "collection.load()\n",
    "print(f'Collection {COLLECTION_NAME} loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get embeddings from OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeding(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=[text]\n",
    "    ).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 1,\n",
    "    \"max_output_tokens\": 4096,\n",
    "    # \"stop_sequences\": [\n",
    "    #     \"<stop>\",\n",
    "    # ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant_response_endswith_eos_token(text: str):\n",
    "    # Matches all the assistant responses in the text except the last one\n",
    "    expr = r'<\\|assistant\\|>\\n(.*?)<\\|user\\|>'\n",
    "    assistant_responses = [x.strip() for x in re.findall(expr, text, re.DOTALL)]\n",
    "    # Last assistant response\n",
    "    assistant_responses.append(text.split('<|assistant|>')[-1].strip())\n",
    "    return not all([x.endswith('</s>') for x in assistant_responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_token_between_calculator_tags(text):\n",
    "    expr = r'<calculator>(.*?)</calculator>'\n",
    "    calculator_expressions = [x.strip() for x in re.findall(expr, text)]\n",
    "    return not all([x.count('<stop>') == 1 for x in calculator_expressions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_open_calc_tags_equal_number_of_close_calc_tags(text):\n",
    "    return not text.count('<calculator>') == text.count('</calculator>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_calculator_calculation_correct(text, debug=False):\n",
    "#     expr = r'<calculator>(.*?)<stop>(.*?)</calculator>'\n",
    "#     calculator_expressions = re.findall(expr, text)\n",
    "#     if debug:\n",
    "#         return [f'{x} -> {eval(x[0]) == eval(x[1])}' for x in calculator_expressions]\n",
    "#     return not all([eval(x[0]) == eval(x[1]) for x in calculator_expressions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_should_not_contain_special_token(text):\n",
    "    spl_tokens = ['<s>', '</s>', '<unk>', '<calculator>', '</calculator>', '<stop>']\n",
    "    expr = r'<\\|user\\|>\\n(.*?)<\\|assistant\\|>'\n",
    "    user_inputs = [x.strip() for x in re.findall(expr, text)]\n",
    "    return not all([not any([x.count(y) > 0 for y in spl_tokens]) for x in user_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_user_inputs_equal_number_of_assistant_responses(text):\n",
    "    return not text.count('<|user|>') == text.count('<|assistant|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_response(text):\n",
    "    return assistant_response_endswith_eos_token(text) or stop_token_between_calculator_tags(text) or number_of_open_calc_tags_equal_number_of_close_calc_tags(text) or user_input_should_not_contain_special_token(text) or number_of_user_inputs_equal_number_of_assistant_responses(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculator(expr: str):\n",
    "#     parsed_expression = ast.parse(expr, mode='eval')\n",
    "#     result = eval(compile(parsed_expression, filename='<string>', mode='eval'))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_response_gemini(text: str = ''):\n",
    "#     response = text + model.generate_content(SYSTEM_PROMPT + text).text.strip()\n",
    "#     if not response.endswith('</s>'):\n",
    "#         # print(response)\n",
    "#         response = f'{response}<stop>{calculator(response[response.rfind('<calculator>') + len('<calculator>'):])}</calculator>'\n",
    "#         return generate_response_gemini(response)\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "global num\n",
    "num=0\n",
    "def insert_data_point():\n",
    "    global num\n",
    "    try:\n",
    "        response = model.generate_content(SYSTEM_PROMPT)\n",
    "        embeding = get_embeding(response.text)\n",
    "\n",
    "        if not test_response(response.text):\n",
    "            collection.insert({\n",
    "                \"embeding\": embeding,\n",
    "                \"conversation\": response.text\n",
    "            })\n",
    "        num += 1\n",
    "        print(f'Inserted data point {num}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        threads = [Thread(target=insert_data_point) for _ in range(MAX_QUERIES_PER_MINUTE)]\n",
    "        for thread in threads: thread.start()\n",
    "        time.sleep(60)\n",
    "        for thread in threads: thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "function_call_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
