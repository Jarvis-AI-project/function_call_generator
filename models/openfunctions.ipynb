{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import openai\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosted Gorilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_gorilla_response(prompt, functions=[], model=\"gorilla-openfunctions-v0\"):\n",
    "#     openai.api_key = \"EMPTY\"\n",
    "#     openai.api_base = \"http://luigi.millennium.berkeley.edu:8000/v1\"\n",
    "#     # openai.api_base = \"https://limcheekin-gorilla-openfunctions-v1-gguf.hf.space/v1\"\n",
    "#     try:\n",
    "#         completion = openai.ChatCompletion.create(\n",
    "#             model=model,\n",
    "#             temperature=0.0,\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#             functions=functions,\n",
    "#         )\n",
    "#         return completion.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         print(e, model, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "# device: str = \"cuda:1\"\n",
    "torch_dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODEL_PATH = \"gorilla-openfunctions-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b67029a95c845849b4a5f120f74b90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(_MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    _MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 0,\n",
       " 'model.layers.0': 0,\n",
       " 'model.layers.1': 0,\n",
       " 'model.layers.2': 0,\n",
       " 'model.layers.3': 0,\n",
       " 'model.layers.4': 0,\n",
       " 'model.layers.5': 0,\n",
       " 'model.layers.6': 0,\n",
       " 'model.layers.7': 0,\n",
       " 'model.layers.8': 0,\n",
       " 'model.layers.9': 0,\n",
       " 'model.layers.10': 0,\n",
       " 'model.layers.11': 0,\n",
       " 'model.layers.12': 0,\n",
       " 'model.layers.13': 0,\n",
       " 'model.layers.14': 0,\n",
       " 'model.layers.15': 0,\n",
       " 'model.layers.16': 1,\n",
       " 'model.layers.17': 1,\n",
       " 'model.layers.18': 1,\n",
       " 'model.layers.19': 1,\n",
       " 'model.layers.20': 1,\n",
       " 'model.layers.21': 1,\n",
       " 'model.layers.22': 1,\n",
       " 'model.layers.23': 1,\n",
       " 'model.layers.24': 1,\n",
       " 'model.layers.25': 1,\n",
       " 'model.layers.26': 1,\n",
       " 'model.layers.27': 1,\n",
       " 'model.layers.28': 1,\n",
       " 'model.layers.29': 1,\n",
       " 'model.layers.30': 1,\n",
       " 'model.layers.31': 1,\n",
       " 'model.norm': 1,\n",
       " 'lm_head': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamer = TextStreamer(tokenizer=tokenizer, skip_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     max_new_tokens=128,\n",
    "#     batch_size=16,\n",
    "#     torch_dtype=torch_dtype,\n",
    "#     streamer=streamer,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(user_query: str, functions: list = []) -> str:\n",
    "    return f\"USER: <<question>> {user_query} <<function>> {json.dumps(functions)}\\nASSISTANT: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'call an ola cab from bhajanpura to nodia sector 62 in twenty two minutes.'\n",
    "# query = 'call an ola cab from bhajanpura to nodia sector 62 in twenty two minutes and then from uber for the same route in 10 minutes.'\n",
    "functions = {\n",
    "        \"name\": \"Call Cab Function\",\n",
    "        \"api_name\": \"cab.ride\",\n",
    "        \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters.\",\n",
    "        \"parameters\":  {\n",
    "            \"start_loc\": {\n",
    "                \"type\": \"string\",\n",
    "                # \"default\": \"current_location\",\n",
    "                \"description\": \"location of the starting place of the uber ride\"\n",
    "            },\n",
    "            \"end_loc\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"location of the ending place of the uber ride\"\n",
    "            },\n",
    "            \"type\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"normal\", \"plus\", \"premium\"],\n",
    "                # \"default\": \"normal\",\n",
    "                \"description\": \"types of uber ride user is ordering\"\n",
    "            },\n",
    "            \"time\": {\n",
    "                \"type\": \"integer\",\n",
    "                # \"default\": \"now\",\n",
    "                \"description\": \"the amount of time in minutes the customer is willing to wait\"\n",
    "            },\n",
    "            \"platform\": {\n",
    "                \"type\": \"string\",\n",
    "                # \"default\": \"uber\",\n",
    "                \"enum\": [\"uber\", \"ola\"],\n",
    "                \"description\": \"the platform the user is ordering the ride from\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"start_loc\", \"end_loc\", \"type\", \"time\", \"platform\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generation_config.temperature = 0.2\n",
    "# model.generation_config.temperature = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER: <<question>> call an ola cab from bhajanpura to nodia sector 62 in twenty two minutes. <<function>> {\"name\": \"Call Cab Function\", \"api_name\": \"cab.ride\", \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters.\", \"parameters\": {\"start_loc\": {\"type\": \"string\", \"description\": \"location of the starting place of the uber ride\"}, \"end_loc\": {\"type\": \"string\", \"description\": \"location of the ending place of the uber ride\"}, \"type\": {\"type\": \"string\", \"enum\": [\"normal\", \"plus\", \"premium\"], \"description\": \"types of uber ride user is ordering\"}, \"time\": {\"type\": \"integer\", \"description\": \"the amount of time in minutes the customer is willing to wait\"}, \"platform\": {\"type\": \"string\", \"enum\": [\"uber\", \"ola\"], \"description\": \"the platform the user is ordering the ride from\"}}, \"required\": [\"start_loc\", \"end_loc\", \"type\", \"time\", \"platform\"]}\\nASSISTANT: '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = get_prompt(query, functions)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving prompt to cuda:0\n"
     ]
    }
   ],
   "source": [
    "# pipe(prompt, max_new_tokens=512, return_full_text=False, do_sample=True)\n",
    "# prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "tokenized_prompt = tokenizer([prompt], return_tensors=\"pt\")\n",
    "if tokenized_prompt['input_ids'].device != model.device:\n",
    "    print(f\"Moving prompt to {model.device}\")\n",
    "    prompt_ids = tokenized_prompt['input_ids'].to(model.device)\n",
    "    attention_mask = tokenized_prompt['attention_mask'].to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,  3148,  1001, 29901,  3532, 12470,  6778,  1246,   385,   288,\n",
       "            433,  7776,   515,   289, 29882,  1175,   273, 29886,  2002,   304,\n",
       "          18778,   423, 17535, 29871, 29953, 29906,   297, 10081,  1023,  6233,\n",
       "          29889,  3532,  2220,  6778,  8853,   978,  1115,   376,  5594, 11680,\n",
       "           6680,   613,   376,  2754, 29918,   978,  1115,   376, 29883,   370,\n",
       "          29889,  2426,   613,   376,  8216,  1115,   376, 12542, 13907, 22203,\n",
       "            363, 20330,  2183,   278,  4423, 29892,  1134,   310, 22203, 29892,\n",
       "            322,   278,  5253,   310,   931,   278, 11962,   338, 17762,   304,\n",
       "           4480,   408,  4128, 19602,   376, 16744,  1115,  8853,  2962, 29918,\n",
       "           2029,  1115,  8853,  1853,  1115,   376,  1807,   613,   376,  8216,\n",
       "           1115,   376,  5479,   310,   278,  6257,  2058,   310,   278,   318,\n",
       "            495, 22203, 10758,   376,   355, 29918,  2029,  1115,  8853,  1853,\n",
       "           1115,   376,  1807,   613,   376,  8216,  1115,   376,  5479,   310,\n",
       "            278, 17140,  2058,   310,   278,   318,   495, 22203, 10758,   376,\n",
       "           1853,  1115,  8853,  1853,  1115,   376,  1807,   613,   376, 18605,\n",
       "           1115,  6796,  8945,   613,   376, 11242,   613,   376,  1457, 29885,\n",
       "           1974, 12436,   376,  8216,  1115,   376,  8768,   310,   318,   495,\n",
       "          22203,  1404,   338, 20520, 10758,   376,  2230,  1115,  8853,  1853,\n",
       "           1115,   376, 16031,   613,   376,  8216,  1115,   376,  1552,  5253,\n",
       "            310,   931,   297,  6233,   278, 11962,   338, 17762,   304,  4480,\n",
       "          10758,   376, 12120,  1115,  8853,  1853,  1115,   376,  1807,   613,\n",
       "            376, 18605,  1115,  6796, 11234,   613,   376,  2963, 12436,   376,\n",
       "           8216,  1115,   376,  1552,  7481,   278,  1404,   338, 20520,   278,\n",
       "          22203,   515, 29908, 11656,   376, 12403,  1115,  6796,  2962, 29918,\n",
       "           2029,   613,   376,   355, 29918,  2029,   613,   376,  1853,   613,\n",
       "            376,  2230,   613,   376, 12120,  3108, 29913,    13, 22933,  9047,\n",
       "          13566, 29901, 29871]], device='cuda:0'),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    prompt_ids,\n",
    "    # max_length=512,\n",
    "    # do_sample=True,\n",
    "    do_sample=False,\n",
    "    # top_p=0.9,\n",
    "    # top_k=0,\n",
    "    # temperature=0.01,\n",
    "    # num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # no_repeat_ngram_size=3,\n",
    "    # repetition_penalty=2.0,\n",
    "    # length_penalty=1.0,\n",
    "    num_beams=1,\n",
    "    # early_stopping=True,\n",
    "    # use_cache=True,\n",
    "    # bad_words_ids=[[tokenizer.eos_token_id]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER: <<question>> List all the devices in the house. <<function>> [{\"name\": \"Check Battery\", \"api_name\": \"devices.battery\", \"description\": \"Check the battery of a device\", \"parameters\": {\"devices\": {\"name\": \"devices\", \"description\": \"list of devices to check the battery of\", \"value\": \"list\"}}, \"required\": [\"devices\"]}, {\"name\": \"Get Devices\", \"api_name\": \"devices.get\", \"description\": \"Get the list of devices\", \"parameters\": [], \"returns\": \"list of devices\"}]\\nASSISTANT:  devices.battery()'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query2 = 'List all the devices in the house and their battery percentage.'\n",
    "query2 = 'List all the devices in the house.'\n",
    "functions2 = [\n",
    "    {\n",
    "        \"name\": \"Check Battery\",\n",
    "        \"api_name\": \"devices.battery\",\n",
    "        \"description\": \"Check the battery of a device\",\n",
    "        \"parameters\":  {\n",
    "            \"devices\": {\n",
    "                \"name\": \"devices\",\n",
    "                \"description\": \"list of devices to check the battery of\",\n",
    "                \"value\": \"list\",\n",
    "                # \"default\": \"all\"\n",
    "            },\n",
    "        },\n",
    "        # \"returns\": \"battery percentage of the device\"\n",
    "        \"required\": [\"devices\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Get Devices\",\n",
    "        \"api_name\": \"devices.get\",\n",
    "        \"description\": \"Get the list of devices\",\n",
    "        \"parameters\":  [],\n",
    "        \"returns\": \"list of devices\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER: <<question>> List all the devices in the house. <<function>> [{\"name\": \"Check Battery\", \"api_name\": \"devices.battery\", \"description\": \"Check the battery of a device\", \"parameters\": {\"devices\": {\"name\": \"devices\", \"description\": \"list of devices to check the battery of\", \"value\": \"list\"}}, \"required\": [\"devices\"]}, {\"name\": \"Get Devices\", \"api_name\": \"devices.get\", \"description\": \"Get the list of devices\", \"parameters\": [], \"returns\": \"list of devices\"}]\\nASSISTANT: '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = get_prompt(query2, functions2)\n",
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving prompt to cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenized_prompt2 = tokenizer([prompt2], return_tensors=\"pt\")\n",
    "if tokenized_prompt2['input_ids'].device != model.device:\n",
    "    print(f\"Moving prompt to {model.device}\")\n",
    "    prompt_ids2 = tokenized_prompt2['input_ids'].to(model.device)\n",
    "    attention_mask2 = tokenized_prompt2['attention_mask'].to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    prompt_ids2,\n",
    "    # max_length=512,\n",
    "    # do_sample=True,\n",
    "    do_sample=False,\n",
    "    # top_p=0.9,\n",
    "    # top_k=0,\n",
    "    # temperature=0.01,\n",
    "    # num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    # no_repeat_ngram_size=3,\n",
    "    # repetition_penalty=2.0,\n",
    "    # length_penalty=1.0,\n",
    "    num_beams=1,\n",
    "    # early_stopping=True,\n",
    "    # use_cache=True,\n",
    "    # bad_words_ids=[[tokenizer.eos_token_id]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER: <<question>> List all the devices in the house. <<function>> [{\"name\": \"Check Battery\", \"api_name\": \"devices.battery\", \"description\": \"Check the battery of a device\", \"parameters\": {\"devices\": {\"name\": \"devices\", \"description\": \"list of devices to check the battery of\", \"value\": \"list\"}}, \"required\": [\"devices\"]}, {\"name\": \"Get Devices\", \"api_name\": \"devices.get\", \"description\": \"Get the list of devices\", \"parameters\": [], \"returns\": \"list of devices\"}]\\nASSISTANT:  devices.battery()'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "output_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
